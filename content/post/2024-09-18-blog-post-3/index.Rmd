---
title: Blog Post 3
author: Victor Bowker
date: '2024-09-18'
slug: blog-post-3
categories: []
tags: []
---
```{r, echo=FALSE, warning = FALSE, message = FALSE}
library(car)
library(caret)
library(CVXR)
library(glmnet)
library(tidyverse)

```

```{r, echo=FALSE, warning = FALSE, message = FALSE}

d_pollav_natl <- read_csv("national_polls_1968-2024.csv")
d_pollav_state <- read_csv("state_polls_1968-2024.csv")
```


**Poll Averages by Date from 2020**

Take a look at this graph below, showing party polling in the year leading up to the Election in November of 2020. Check out the increases and decreases and scroll further to find some important dates and how that impacted polling!

```{r, echo=FALSE, warning = FALSE, message = FALSE}
d_pollav_natl |> 
  filter(year == 2020) |> 
  ggplot(aes(x = poll_date, y = poll_support, color = party)) +
  geom_point(size = 1) + 
  geom_line() + 
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("dodgerblue4", "firebrick1")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2020") + 
  theme_classic()

```


Next, see where the DNC and RNC were held. Notice that while it was not instant, there is a minor increase in support for both parties following their debates. You will find in my analysis of 538's polling forecast tool that they specifically tone down polling increases in the week following a party's convention. 538 journalist G. Elliot Morris says that this section of the foreceast is important as both Clinton and Trump showed their greatest polling in the week following their respective conventions in 2016.

```{r, echo=FALSE, warning = FALSE, message = FALSE}
d_pollav_natl |> 
  filter(year == 2020) |> 
  ggplot(aes(x = poll_date, y = poll_support, color = party)) +
  geom_rect(xmin = as.Date("2020-08-17"), xmax = as.Date("2020-08-20"), ymin = 47.5, ymax = 100, alpha = 0.1, color = NA, fill = "grey") + 
  annotate("text", x = as.Date("2020-08-07"), y = 51.5, label = "DNC", size = 4) + 
  geom_rect(xmin = as.Date("2020-08-24"), xmax = as.Date("2020-08-27"), ymin = 0, ymax = 46, alpha = 0.1, color = NA, fill = "grey") +
  annotate("text", x = as.Date("2020-09-04"), y = 45, label = "RNC", size = 4) +
  geom_point(size = 1) + 
  geom_line() + 
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("dodgerblue4", "firebrick1")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2020 (with Conference Dates)") + 
  theme_classic()

```

**Interesting Factors-Do They Matter?**



Next, you will see some added dates that pollsters assumed might impact results. Check out how they really did impact it! 
```{r, echo=FALSE, warning = FALSE, message = FALSE}
d_pollav_natl |> 
  filter(year == 2020) |> 
  ggplot(aes(x = poll_date, y = poll_support, color = party)) +
  geom_rect(xmin = as.Date("2020-08-17"), xmax = as.Date("2020-08-20"), ymin = 47.5, ymax = 100, alpha = 0.1, color = NA, fill = "grey") + 
  annotate("text", x = as.Date("2020-08-07"), y = 51.5, label = "DNC", size = 4) +
  geom_rect(xmin = as.Date("2020-08-24"), xmax = as.Date("2020-08-27"), ymin = 0, ymax = 47.2, alpha = 0.1, color = NA, fill = "grey") +
  annotate("text", x = as.Date("2020-09-04"), y = 45, label = "RNC", size = 4) +
  geom_rect(xmin = as.Date("2020-10-02"), xmax = as.Date("2020-10-12"), ymin = 0, ymax = 42.7, alpha = 0.05, color = NA, fill = "grey") +
  
  geom_point(size = 1) + 
  geom_line() + 
  
  geom_segment(x = as.Date("2020-03-12"), xend = as.Date("2020-03-12"), y = 0, yend = 44.8, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-03-12"), y = 42.5, label = "COVID \n Market Crash", size = 3) +
  geom_segment(x = as.Date("2020-04-08"), xend = as.Date("2020-04-08"), y = 49, yend = 100, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-03-25"), y = 51.3, label = "Bernie Ends Run", size = 3) +
  geom_segment(x = as.Date("2020-04-16"), xend = as.Date("2020-04-16"), y = 0, yend = 44, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-04-16"), y = 44.7, label = "22 mil \n Unemployment", size = 3) +
  geom_segment(x = as.Date("2020-05-27"), xend = as.Date("2020-05-27"), y = 0, yend = 43, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-06-05"), y = 44, label = "100k COVID Dead, \n George Floyd", size = 3) +
  
  geom_segment(x = as.Date("2020-07-14"), xend = as.Date("2020-07-14"), y = 0, yend = 50.3, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-06-19"), y = 47.5, label = "Moderna Announces", size = 3) +
  
  geom_segment(x = as.Date("2020-09-29"), xend = as.Date("2020-09-29"), y = 50, yend = 100, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-9-12"), y = 49.5, label = "Pres. Debate", size = 3) +
  geom_segment(x = as.Date("2020-10-07"), xend = as.Date("2020-10-07"), y = 51.7, yend = 100, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-10-17"), y = 50.3, label = "VP Debate", size = 3) +
  geom_segment(x = as.Date("2020-10-22"), xend = as.Date("2020-10-22"), y = 52, yend = 100, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-10-30"), y = 51.5, label = "Pres. Debate", size = 3) +
  annotate("text", x = as.Date("2020-10-15"), y = 43.7, label = "Trump Has COVID", size = 3) +
  geom_segment(x = as.Date("2020-09-18"), xend = as.Date("2020-09-18"), y = 50, yend = 100, linetype = "dashed", alpha = 0.4, color = "grey") +
  annotate("text", x = as.Date("2020-09-03"), y = 51.5, label = "RBG Passes", size = 3) +
  
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("dodgerblue4", "firebrick1")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2020 (with Game Changers?)") + 
  theme_classic()

```

  Allow me to point you to a few key dates that had an incredible impact! First, when Bernie Sanders dropped out, Biden's polling first dropped, but then elevated quite quickly. I believe there was this delay because Sanders waited at least 6 days to officially endorse Biden, meaning his supporters had not yet moved to support Biden. 

  Next, see where the elevation of COVID deaths, tied in with the death of George Floyd, Trump's poll approval dropped quite heavily, allowing the Democrats to swoop in and elevate their polling quite substantially. Also, the Dems rode an impressive wave of increasing approval through a serious of Presidential and Vice Presidential debates.
  
  Finally, Trump's bought with COVID did not help his polling. Especially considering his position on COVID, calling some victims weak or obese, it was not helpful for him to then fall ill with the very disease!
  


```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_pollav_natl |>
  filter(year == 1988) |>
  ggplot(aes(x = poll_date, y = poll_support, color = party)) +
  geom_rect(xmin=as.Date("1988-07-18"), xmax=as.Date("1988-07-21"), ymin=47, ymax=100, alpha=0.1, colour=NA, fill="grey") +
  annotate("text", x=as.Date("1988-07-10"), y=50, label="DNC", size=4) +
  geom_rect(xmin=as.Date("1988-08-15"), xmax=as.Date("1988-08-18"), ymin=0, ymax=44, alpha=0.1, colour=NA, fill="grey") +
  annotate("text", x=as.Date("1988-08-26"), y=40, label="RNC", size=4) +
  
  geom_point(size = 1) +
  geom_line() + 
  
  geom_segment(x=as.Date("1988-09-13"), xend=as.Date("1988-09-13"), y=49, yend=100, lty=2, color="grey", alpha=0.4) +
  annotate("text", x=as.Date("1988-09-13"), y=52, label="Tank Gaffe\n(?)", size=3) +
  annotate("text", x=as.Date("1988-09-21"), y=57, label="Willie Horton Ad\n(?)", size=3) +
  geom_segment(x=as.Date("1988-09-21"), xend=as.Date("1988-09-21"), y=49, yend=100, lty=2, color="grey", alpha=0.4) +
  annotate("text", x=as.Date("1988-10-15"), y=64, label="First Debate\n(Death\nPenalty\nGaffe)", size=3) +
  geom_segment(x=as.Date("1988-10-15"), xend=as.Date("1988-10-15"), y=49, yend=100, lty=2, color="grey", alpha=0.4) +
  scale_x_date(date_labels = "%b, %Y") +
  scale_color_manual(values = c("dodgerblue4","firebrick1")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 1988 (with Game Changers?)") + 
  theme_classic()

```


**Now Considering 2024 Facts**

You will see below the data _so far_ from this election cycle. The data is loud, and it is telling us that the Democrats switching to Vice President Kamala Harris was the _only_ choice. We see the Dem's approval skyrocket from 40, to 45 percent points. Trump experienced some impressive gains as Biden fell, though VP Harris was able to take off quite well once she gained a footing in the race.


```{r, echo=FALSE, warning = FALSE, message = FALSE}

d_pollav_natl |> 
  filter(year == 2024) |> 
  ggplot(aes(x = poll_date, y = poll_support, color = party)) +
  geom_point(size = 1) + 
  geom_line() + 
  scale_x_date(date_labels = "%b %d") + 
  scale_color_manual(values = c("dodgerblue4", "firebrick1")) +
  labs(x = "Date",
       y = "Average Poll Approval", 
       title = "Polling Averages by Date, 2024") + 
  theme_classic()

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_vote <- read_csv("popvote_1948-2020.csv")
d_vote$party[d_vote$party == "democrat"] <- "DEM"
d_vote$party[d_vote$party == "republican"] <- "REP"


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_poll_nov <- d_vote |> 
  left_join(d_pollav_natl |> 
              group_by(year, party) |> 
              top_n(1, poll_date) |> 
              select(-candidate), 
            by = c("year", "party")) |> 
  rename(nov_poll = poll_support) |> 
  filter(year <= 2020) |> 
  drop_na()

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
ols.nov.1 <- lm(pv2p ~ nov_poll, 
                data = subset(d_poll_nov, party == "DEM"))
summary(ols.nov.1)

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
ols.nov.2 <- lm(pv2p ~ nov_poll, 
                data = d_poll_nov)
summary(ols.nov.2)

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_poll_weeks <- d_pollav_natl |> 
  group_by(year, party, weeks_left) |>
  summarize(mean_poll_week = mean(poll_support)) |> 
  filter(weeks_left <= 30) |> 
  pivot_wider(names_from = weeks_left, values_from = mean_poll_week) |> 
  left_join(d_vote, by = c("year", "party"))

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_poll_weeks_train <- d_poll_weeks |> 
  filter(year <= 2020)
d_poll_weeks_test <- d_poll_weeks |> 
  filter(year == 2024)

colnames(d_poll_weeks)[3:33] <- paste0("poll_weeks_left_", 0:30)
colnames(d_poll_weeks_train)[3:33] <- paste0("poll_weeks_left_", 0:30)
colnames(d_poll_weeks_test)[3:33] <- paste0("poll_weeks_left_", 0:30)

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
ols.pollweeks <- lm(paste0("pv2p ~ ", paste0( "poll_weeks_left_", 0:30, collapse = " + ")), 
                    data = d_poll_weeks_train)
summary(ols.pollweeks) # N.B. Inestimable: p (31) > n (30)! 

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
x.train <- d_poll_weeks_train |>
  ungroup() |> 
  select(all_of(starts_with("poll_weeks_left_"))) |> 
  as.matrix()
y.train <- d_poll_weeks_train$pv2p

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
ridge.pollsweeks <- glmnet(x = x.train, y = y.train, alpha = 0) # Set ridge using alpha = 0. 


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
plot(ridge.pollsweeks, xvar = "lambda")


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
coef(ridge.pollsweeks, s = 0.1)


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
lasso.pollsweeks <- glmnet(x = x.train, y = y.train, alpha = 1) # Set lasso using alpha = 1.


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
plot(lasso.pollsweeks, xvar = "lambda")


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
coef(lasso.pollsweeks, s = 0.1)


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
enet.pollsweeks <- glmnet(x = x.train, y = y.train, alpha = 0.5) # Set elastic net using alpha = 0.5.


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
plot(enet.pollsweeks, xvar = "lambda")


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
cv.ridge.pollweeks <- cv.glmnet(x = x.train, y = y.train, alpha = 0)
cv.lasso.pollweeks <- cv.glmnet(x = x.train, y = y.train, alpha = 1)
cv.enet.pollweeks <- cv.glmnet(x = x.train, y = y.train, alpha = 0.5)

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
lambda.min.ridge <- cv.ridge.pollweeks$lambda.min
lambda.min.lasso <- cv.lasso.pollweeks$lambda.min
lambda.min.enet <- cv.enet.pollweeks$lambda.min

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
(mse.ridge <- mean((predict(ridge.pollsweeks, s = lambda.min.ridge, newx = x.train) - y.train)^2))
(mse.lasso <- mean((predict(lasso.pollsweeks, s = lambda.min.lasso, newx = x.train) - y.train)^2))
(mse.enet <- mean((predict(enet.pollsweeks, s = lambda.min.enet, newx = x.train) - y.train)^2))

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d.coefplot <- data.frame("OLS" = coef(ols.pollweeks)[-1], 
                         "Ridge" = coef(ridge.pollsweeks, s = lambda.min.ridge)[-1], 
                         "Lasso" = coef(lasso.pollsweeks, s = lambda.min.lasso)[-1], 
                         "Elastic Net" = coef(enet.pollsweeks, s = lambda.min.enet)[-1]) |> 
  rownames_to_column("coef_name") |> 
  pivot_longer(cols = -coef_name, names_to = "method", values_to = "coef_est") |> 
  mutate(week = rep(0:30, each = 4))

d.coefplot[which(is.na(d.coefplot$coef_est)),]$coef_est <- 0 

d.coefplot |>
  ggplot(aes(x = coef_est, y = reorder(coef_name, -week), color = method)) +
  geom_segment(aes(xend = 0, yend = reorder(coef_name, -week)), alpha = 0.5, lty = "dashed") +
  geom_vline(aes(xintercept = 0), lty = "dashed") +   
  geom_point() + 
  labs(x = "Coefficient Estimate", 
       y = "Coefficient Name", 
       title = "Comparison of Coefficients Across Regularization Methods") + 
  theme_classic()

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_pollav_natl |> 
  filter(year == 2024) |> 
  select(weeks_left) |> 
  distinct() |> 
  range()

x.train <- d_poll_weeks_train |>
  ungroup() |> 
  select(all_of(paste0("poll_weeks_left_", 7:30))) |> 
  as.matrix()
y.train <- d_poll_weeks_train$pv2p
x.test <- d_poll_weeks_test |>
  ungroup() |> 
  select(all_of(paste0("poll_weeks_left_", 7:30))) |> 
  as.matrix()

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
set.seed(02138)
enet.poll <- cv.glmnet(x = x.train, y = y.train, alpha = 0.5)
lambda.min.enet.poll <- enet.poll$lambda.min

```


**Projection**

Utilizing some intense code that was lovingly provided by Teaching Fellow Matthew Dardet, we run a regularized regression from current polling data to find who is looking best in the polls. Code is accesible via GitHub, but allow me to briefly explain.

First, we are using a datset that includes all popular voteshare data from 1948 to 2020. Using poll data from the above datasets, we can start to merge and focus on November information. As we get closer to the election, every week counts, so we split up data by week. Nearly ever news cycle could reflect updated polling data, but lets not get _too_ intense. Then, we run regressions, with the normal foreceast as well as an OLS (ordinary least squares) forecast. Finally, with some intense math that a _mere_ Gov concentrator such as myself may not fully understand, we have results!  

It looks as though Harris demonstrates an incredibly narrow edge, certainly within the margin of error. Lets keep watching to see!

```{r, echo=FALSE, message=FALSE, warning=FALSE}
(polls.pred <- predict(enet.poll, s = lambda.min.enet.poll, newx = x.test))


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_econ <- read_csv("fred_econ.csv") |> 
  filter(quarter == 2)

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_combined <- d_econ |> 
  left_join(d_poll_weeks, by = "year") |> 
  filter(year %in% c(unique(d_vote$year), 2024)) |> 
  group_by(party) |> 
  mutate(pv2p_lag1 = lag(pv2p, 1), 
         pv2p_lag2 = lag(pv2p, 2)) |> 
  ungroup() |> 
  mutate(gdp_growth_x_incumbent = GDP_growth_quarterly * incumbent, 
         rdpi_growth_quarterly = RDPI_growth_quarterly * incumbent,
         cpi_x_incumbent = CPI * incumbent,
         unemployment_x_incumbent = unemployment * incumbent,
         sp500_x_incumbent = sp500_close * incumbent) 

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_fund <- d_combined |> 
  select("year", "pv2p", "GDP", "GDP_growth_quarterly", "RDPI", "RDPI_growth_quarterly", "CPI", "unemployment", "sp500_close",
         "incumbent", "gdp_growth_x_incumbent", "rdpi_growth_quarterly", "cpi_x_incumbent", "unemployment_x_incumbent", "sp500_x_incumbent", 
         "pv2p_lag1", "pv2p_lag2") 
x.train.fund <- d_fund |> 
  filter(year <= 2020) |>
  select(-c(year, pv2p)) |> 
  slice(-c(1:9)) |> 
  as.matrix()
y.train.fund <- d_fund |> 
  filter(year <= 2020) |> 
  select(pv2p) |> 
  slice(-c(1:9)) |> 
  as.matrix()
x.test.fund <- d_fund |> 
  filter(year == 2024) |> 
  select(-c(year, pv2p)) |> 
  drop_na() |> 
  as.matrix()

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
set.seed(02138)
enet.fund <- cv.glmnet(x = x.train.fund, y = y.train.fund, intercept = FALSE, alpha = 0.5)
lambda.min.enet.fund <- enet.fund$lambda.min

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}

(fund.pred <- predict(enet.fund, s = lambda.min.enet.fund, newx = x.test.fund))

```

```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
d_combo <- d_combined |> 
  select("year", "pv2p", "GDP", "GDP_growth_quarterly", "RDPI", "RDPI_growth_quarterly", "CPI", "unemployment", "sp500_close",
         "incumbent", "gdp_growth_x_incumbent", "rdpi_growth_quarterly", "cpi_x_incumbent", "unemployment_x_incumbent", "sp500_x_incumbent", 
         "pv2p_lag1", "pv2p_lag2", all_of(paste0("poll_weeks_left_", 7:30))) 

x.train.combined <- d_combo |> 
  filter(year <= 2020) |> 
  select(-c(year, pv2p)) |> 
  slice(-c(1:9)) |> 
  as.matrix()
y.train.combined <- d_combo |>
  filter(year <= 2020) |> 
  select(pv2p) |> 
  slice(-c(1:9)) |> 
  as.matrix()
x.test.combined <- d_combo |>
  filter(year == 2024) |> 
  select(-c(year, pv2p)) |> 
  drop_na() |> 
  as.matrix()

```

```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}

set.seed(02138)
enet.combined <- cv.glmnet(x = x.train.combined, y = y.train.combined, intercept = FALSE, alpha = 0.5)
lambda.min.enet.combined <- enet.combined$lambda.min
```

```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}

(combo.pred <- predict(enet.combined, s = lambda.min.enet.combined, newx = x.test.combined))

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
(unweighted.ensemble.pred <- (polls.pred + fund.pred)/2)


```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}
election_day_2024 <- "2024-11-05"
today <- "2024-09-18"
days_left <- as.numeric(as.Date(election_day_2024) - as.Date(today))

(poll_model_weight <- 1- (1/sqrt(days_left)))
(fund_model_weight <- 1/sqrt(days_left))

(ensemble.2.pred <- polls.pred * poll_model_weight + fund.pred * fund_model_weight)  

```
```{r, echo=FALSE, warning = FALSE, message = FALSE, include=FALSE}

(poll_model_weight <- 1/sqrt(days_left))
(fund_model_weight <- 1-(1/sqrt(days_left)))

(ensemble.3.pred <- polls.pred * poll_model_weight + fund.pred * fund_model_weight)
```

**Extension Comparing Silver and Morris**

  In 538’s polling, they have created a forecast model that ties many factors together for what they hope is the most accurate prediction of the election. First, they make some tweaks to the data to account for a few key events. In the days of and soon after a national convention, 538 makes downward adjustments to make up for the likely uptick in support. They made it clear that these recalibrations only occur if there was a substantial change in support, so candidates with little change are not impacted. 538 justifies this because both Trump and Clinton had their highest daily polling averages in the week during and after their respective national conventions. 
	Additionally, 538 is not afraid to make calculated assumptions about certain regions of America. Their forecasting model will detect an uptick in support for Biden in Maine, and begin to raise projections for him in Vermont New Hampshire, or other like-minded New England states. 538 has set up a map of 10 regions across the US that represent geographically, economically, and socially similar groups of states. My favorite of those groups is Tex-ish, which includes the great states of Texas, Louisiana, and Oklahoma. 
	Next, 538 polls on buckets of factors, like economic indicators including jobs, spending, personal income, and manufacturing. The motivation for these distinctions comes from the issue of only tracking GDP: it is too slow. The model has been trained on historical measures of this data, some of which go back nearly 100 years. Another bucket includes info on political factors, like office incumbency status or party incumbency status. By combining fundamental measures of economic growth and public opinion with this new, advanced forecast model, 538 is able to present an incredibly accurate prediction of the next election!

  Nate Silver, a former 538 pollster, has a similar forecast model, with a few key differences. The last presidential election under Silver’s purview was 2020, meaning there were extensive COVID adjustments that have to now be subtracted from the equation. COVID is simply not a factor of any grand scale in this election.
	Silver also has seen a change in who turns out for elections, leading to a change in the forecast model. With evidence from special elections and primaries, it is clear that Republicans no longer turn out in larger numbers than Democrats. Adjustments to scale who answer polls now have to shift from turning down Republican responses to Democratic ones. He is also planning to fully phase out this turnout measurement before Election Day. 
	Another important factor that was phased out this term is the Cost of Voting Index. This measurement assumed that as states loosened laws surrounding voting, like same-day registration, Democrats would benefit. Alternatively, if a state was to shorten polling place hours, or restrict registration, Republicans would be likely to benefit. Silver has deemed this an ineffective metric and has removed it from his forecast. 
	Next, Silver had to consider the presence of a third-party named candidate. In this race, Robert Kennedy Jr. was running as an Independent candidate before dropping out and supporting Former President Trump. 2020 had no impactful third-party candidate, but 2016 did have Gary Johnson, for whom the forecast was originally based. Silver found that third-party candidates usually started with decent polling, before slowly fading as Election Day loomed. Additionally, polls utilized varied wording for a third-party candidate, further confusing the ability to accurately measure popular opinion on less mainstream candidates. 
	Finally, Silver had to consider this race being a presidential rematch, where Biden took on Trump a second time. This has since changed now that the Democratic candidate has switched from President Joe Biden to Vice President Kamala Harris. Now, the reliability of pre-dropout data is difficult to trust or demonstrate change. 

Overall, I believe that 538’s approach is stronger, exactly because it glazes over some of Silver’s nuance. When you hyper-fixate on these small characteristics of an election, it is very possible that the forecast can be more accurate–but we are also fully aware that a very small amount of voters in key swing districts in key swing states will decide this election. 

End of Story!

